"""LLM interface for generating refactoring suggestions using Claude API."""

import re
import time
from dataclasses import dataclass
from typing import Optional, List
import xml.etree.ElementTree as ET

from genec.core.cluster_detector import Cluster
from genec.core.dependency_analyzer import ClassDependencies
from genec.core.cluster_context_builder import ClusterContextBuilder
from genec.llm import (
    AnthropicClientWrapper,
    LLMConfig,
    LLMRequestFailed,
    LLMServiceUnavailable,
)
from genec.core.evolutionary_miner import EvolutionaryData
from genec.utils.logging_utils import get_logger

logger = get_logger(__name__)


@dataclass
class RefactoringSuggestion:
    """Represents a refactoring suggestion generated by the LLM."""
    cluster_id: int
    proposed_class_name: str
    rationale: str
    new_class_code: str
    modified_original_code: str
    cluster: Optional[Cluster] = None


class LLMInterface:
    """Interface for interacting with Claude API to generate refactoring suggestions."""

    def __init__(
        self,
        api_key: Optional[str] = None,
        model: str = 'claude-sonnet-4-20250514',
        max_tokens: int = 4000,
        temperature: float = 0.3,
        timeout: int = 120,
        use_chunking: bool = True
    ):
        """
        Initialize LLM interface.

        Args:
            api_key: Anthropic API key (uses ANTHROPIC_API_KEY env var if not provided)
            model: Claude model to use
            max_tokens: Maximum tokens in response
            temperature: Sampling temperature
            timeout: Request timeout in seconds
            use_chunking: Whether to use AST-based chunking for large classes (recommended)
        """
        self.logger = get_logger(f"GenEC.{self.__class__.__name__}")
        self.model = model
        self.max_tokens = max_tokens
        self.temperature = temperature
        self.timeout = timeout
        self.use_chunking = use_chunking

        # Initialize context builder for chunking
        if self.use_chunking:
            self.context_builder = ClusterContextBuilder()
            self.logger.info("AST-based chunking enabled for token optimization")
        else:
            self.context_builder = None
            self.logger.info("Using full class code in prompts (legacy mode)")

        llm_config = LLMConfig(
            model=self.model,
            timeout=self.timeout,
        )
        self.llm = AnthropicClientWrapper(api_key=api_key, config=llm_config)
        if not self.llm.enabled:
            self.logger.warning(
                "Anthropic API key not provided; LLM-based suggestions will be skipped."
            )
        self._available = self.llm.enabled

    def generate_refactoring_suggestion(
        self,
        cluster: Cluster,
        original_code: str,
        class_deps: ClassDependencies,
        evo_data: Optional[EvolutionaryData] = None,
        max_retries: int = 3
    ) -> Optional[RefactoringSuggestion]:
        """
        Generate a refactoring suggestion for a cluster using Claude.

        Args:
            cluster: Cluster to extract
            original_code: Full source code of original class
            class_deps: Class dependencies
            max_retries: Maximum retry attempts

        Returns:
            RefactoringSuggestion or None if generation fails
        """
        self.logger.info(f"Generating refactoring suggestion for cluster {cluster.id}")

        if not self._available:
            self.logger.info("LLM client unavailable; skipping suggestion generation.")
            return None

        # Build prompt
        prompt = self._build_prompt(cluster, original_code, class_deps, evo_data)

        # Call Claude API with retries
        for attempt in range(max_retries):
            try:
                response = self._call_claude(prompt)
                if response:
                    # Parse response
                    suggestion = self._parse_response(response, cluster)
                    if suggestion:
                        self.logger.info(
                            f"Successfully generated suggestion: {suggestion.proposed_class_name}"
                        )
                        return suggestion
                    else:
                        self.logger.warning(f"Failed to parse response (attempt {attempt + 1})")

            except (LLMServiceUnavailable, LLMRequestFailed) as e:
                self.logger.error(
                    f"LLM call failed (attempt {attempt + 1}): {e}"
                )

                if attempt < max_retries - 1:
                    # Exponential backoff
                    wait_time = 2 ** attempt
                    self.logger.info(f"Retrying in {wait_time} seconds...")
                    time.sleep(wait_time)
            except Exception as e:
                self.logger.error(f"Unexpected error during LLM call (attempt {attempt + 1}): {e}")
                if attempt < max_retries - 1:
                    wait_time = 2 ** attempt
                    self.logger.info(f"Retrying in {wait_time} seconds...")
                    time.sleep(wait_time)

        self.logger.error(f"Failed to generate suggestion after {max_retries} attempts")
        return None

    def _build_prompt(
        self,
        cluster: Cluster,
        original_code: str,
        class_deps: ClassDependencies,
        evo_data: Optional[EvolutionaryData] = None
    ) -> str:
        """
        Build structured prompt for Claude.
        
        Optimized for JDT-based generation: sends only signatures and fields
        to minimize token usage while still allowing for accurate naming.
        """
        methods = cluster.get_methods()
        fields = cluster.get_fields()

        # Build a lightweight representation of the cluster members
        # We don't need the full body to name the class, just signatures + javadoc summary
        member_context = []
        
        if methods:
            member_context.append("Methods:")
            for m in methods:
                javadoc = self._extract_javadoc_summary(m, original_code)
                if javadoc:
                    member_context.append(f"  - {m}")
                    member_context.append(f"    Description: {javadoc}")
                else:
                    member_context.append(f"  - {m}")
        
        if fields:
            member_context.append("Fields:")
            for f in fields:
                member_context.append(f"  - {f}")
                
        context_str = "\n".join(member_context)

        # Format evolutionary context
        evo_context = self._format_evolutionary_context(cluster, evo_data) if evo_data else ""

        prompt = f"""You are a software refactoring expert. Your task is to apply the Extract Class refactoring pattern.
I have identified a cluster of cohesive methods and fields that should be extracted from a large God Class.

**Cluster Members (Signatures & Context):**
{context_str}

{evo_context}

**Your Task:**
1. Analyze the method names, signatures, and descriptions to understand the responsibility of this cluster.
2. Propose a descriptive class name (Java convention) for this new class.
3. Write a brief rationale (2-3 sentences) explaining why these members belong together.

**Output Format:**
Provide your response in the following XML format:

<class_name>ProposedClassName</class_name>

<rationale>
Your explanation here.
</rationale>

Please provide only the XML tags specified above."""

        return prompt

    def _call_claude(self, prompt: str) -> Optional[str]:
        """
        Call Claude API with the prompt.

        Args:
            prompt: Formatted prompt

        Returns:
            Response text or None
        """
        if not self._available:
            return None

        try:
            return self.llm.send_message(
                prompt,
                model=self.model,
                max_tokens=self.max_tokens,
                temperature=self.temperature,
            )
        except (LLMServiceUnavailable, LLMRequestFailed):
            raise

    def _parse_response(
        self,
        response: str,
        cluster: Cluster
    ) -> Optional[RefactoringSuggestion]:
        """
        Parse Claude's response to extract structured information.

        Args:
            response: Raw response text
            cluster: Original cluster

        Returns:
            RefactoringSuggestion or None if parsing fails
        """
        try:
            # Extract class name
            class_name = self._extract_xml_tag(response, 'class_name')
            if not class_name:
                self.logger.error("Failed to extract class_name")
                return None

            # Extract rationale
            rationale = self._extract_xml_tag(response, 'rationale')
            if not rationale:
                self.logger.error("Failed to extract rationale")
                return None

            return RefactoringSuggestion(
                cluster_id=cluster.id,
                proposed_class_name=class_name.strip(),
                rationale=rationale.strip(),
                new_class_code="",
                modified_original_code="",
                cluster=cluster
            )

        except Exception as e:
            self.logger.error(f"Error parsing response: {e}")
            return None

    def _extract_xml_tag(self, text: str, tag: str) -> Optional[str]:
        """
        Extract content from XML tag.

        Args:
            text: Text containing XML tags
            tag: Tag name to extract

        Returns:
            Tag content or None
        """
        # Try regex first (more robust for malformed XML)
        pattern = f'<{tag}>(.*?)</{tag}>'
        match = re.search(pattern, text, re.DOTALL)
        if match:
            return match.group(1)

        # Fallback to XML parsing
        try:
            # Wrap in root element
            wrapped = f'<root>{text}</root>'
            root = ET.fromstring(wrapped)
            element = root.find(tag)
            if element is not None and element.text:
                return element.text
        except Exception as e:
            self.logger.debug(f"XML parsing failed: {e}")

        return None

    def _clean_code(self, code: str) -> str:
        """
        Clean code by removing markdown code blocks and extra whitespace.

        Args:
            code: Code string potentially with markdown

        Returns:
            Cleaned code
        """
        # Remove markdown code blocks
        code = re.sub(r'```java\s*', '', code)
        code = re.sub(r'```\s*', '', code)

        # Remove leading/trailing whitespace from each line
        lines = code.split('\n')
        cleaned_lines = [line.rstrip() for line in lines]

        # Remove leading empty lines
        while cleaned_lines and not cleaned_lines[0].strip():
            cleaned_lines.pop(0)

        # Remove trailing empty lines
        while cleaned_lines and not cleaned_lines[-1].strip():
            cleaned_lines.pop()

        return '\n'.join(cleaned_lines)

    def generate_batch_suggestions(
        self,
        clusters: List[Cluster],
        original_code: str,
        class_deps: ClassDependencies,
        max_suggestions: int = 5
    ) -> List[RefactoringSuggestion]:
        """
        Generate refactoring suggestions for multiple clusters.

        Args:
            clusters: List of clusters to process
            original_code: Original class code
            class_deps: Class dependencies
            max_suggestions: Maximum number of suggestions to generate

        Returns:
            List of successfully generated suggestions
        """
        if not self._available:
            self.logger.info("LLM client unavailable; returning no suggestions.")
            return []

        suggestions = []

        for i, cluster in enumerate(clusters[:max_suggestions], 1):
            self.logger.info(f"Processing cluster {i}/{min(len(clusters), max_suggestions)}")

            suggestion = self.generate_refactoring_suggestion(
                cluster, original_code, class_deps
            )

            if suggestion:
                suggestions.append(suggestion)

            # Rate limiting - small delay between requests
            if i < min(len(clusters), max_suggestions):
                time.sleep(1)

        self.logger.info(f"Generated {len(suggestions)} suggestions")

        return suggestions

    def is_available(self) -> bool:
        """Return True if the LLM client is ready for use."""
        return self._available

    def _extract_javadoc_summary(self, method_signature: str, original_code: str) -> Optional[str]:
        """
        Extract the first sentence of the Javadoc for a given method.
        
        Args:
            method_signature: The signature of the method to find.
            original_code: The full source code.
            
        Returns:
            The first sentence of the Javadoc, or None if not found.
        """
        try:
            # Extract method name from signature
            # Signature format: "public void methodName(Args...)"
            match = re.search(r'\s+(\w+)\(', method_signature)
            if not match:
                return None
            method_name = match.group(1)
            
            # Find the method definition in the code
            # This is a heuristic regex; it might not be perfect but works for most standard Java formatting
            # Look for Javadoc block followed by method definition
            # (/\*\*.*?\*/)\s*(?:@\w+\s*)*.*?\s+methodName\(
            
            # Escape method name for regex
            safe_name = re.escape(method_name)
            
            # Regex to find Javadoc before the method
            # 1. Capture Javadoc group
            # 2. Allow annotations and modifiers between Javadoc and method name
            pattern = re.compile(
                r'(/\*\*.*?\*/)\s*(?:@[a-zA-Z0-9_]+\(?.*?\)?\s*)*(?:public|protected|private|static|final|synchronized|native|strictfp|\s)*[\w<>\[\]]+\s+' + safe_name + r'\(',
                re.DOTALL
            )
            
            match = pattern.search(original_code)
            if match:
                javadoc_block = match.group(1)
                # Strip /** and */ and *
                content = re.sub(r'/\*\*|\*/|^\s*\*', '', javadoc_block, flags=re.MULTILINE)
                # Clean up whitespace
                content = ' '.join(content.split())
                # Get first sentence (split by dot followed by space or end of string)
                first_sentence = re.split(r'\.\s', content)[0]
                if first_sentence and not first_sentence.endswith('.'):
                    first_sentence += '.'
                return first_sentence.strip()
                
        except Exception:
            pass
        return None

    def _format_evolutionary_context(self, cluster: Cluster, evo_data: EvolutionaryData) -> str:
        """
        Format evolutionary coupling data for the prompt.
        
        Args:
            cluster: The cluster being extracted.
            evo_data: The evolutionary data.
            
        Returns:
            Formatted string describing historical coupling.
        """
        if not evo_data or not evo_data.cochange_matrix:
            return ""
            
        methods = cluster.get_methods()
        if len(methods) < 2:
            return ""
            
        # Check for strong coupling pairs within the cluster
        strong_couplings = []
        method_names = [re.search(r'\s+(\w+)\(', m).group(1) for m in methods if re.search(r'\s+(\w+)\(', m)]
        
        # We need to map signatures back to the simple names used in evo_data keys if necessary,
        # but evo_data usually stores pairs of (methodA, methodB).
        # Assuming evo_data keys are based on the identifiers found in git diffs.
        
        # Let's just look for any pairs in the cluster that have high co-change counts
        threshold = 2 # Minimum co-changes to mention
        
        # This is a simplification. In a real scenario, we'd need robust mapping.
        # Here we just check if any pair of methods in the cluster has a high co-change count.
        
        count = 0
        total_co_changes = 0
        
        # Iterate over all pairs in the cluster
        import itertools
        for m1, m2 in itertools.combinations(method_names, 2):
            # Check both orders
            pair1 = (m1, m2)
            pair2 = (m2, m1)
            
            c = evo_data.cochange_matrix.get(pair1, 0) + evo_data.cochange_matrix.get(pair2, 0)
            if c >= threshold:
                count += 1
                total_co_changes += c
                if len(strong_couplings) < 3: # Limit to top 3 examples
                    strong_couplings.append(f"{m1} and {m2} ({c} commits)")
        
        if count > 0:
            context = "**Evolutionary Context:**\n"
            context += f"Analysis of git history shows that methods in this cluster frequently change together ({count} strongly coupled pairs).\n"
            context += "Examples of co-evolution:\n"
            for sc in strong_couplings:
                context += f"- {sc}\n"
            context += "This historical coupling reinforces that these methods are logically related and should be refactored together."
            return context
            
        return ""
